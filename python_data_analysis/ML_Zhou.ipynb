{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Iteration 0,cost is 0.741379-------------\n",
      "---------Iteration 1,cost is 0.702059-------------\n",
      "---------Iteration 2,cost is 0.683260-------------\n",
      "---------Iteration 3,cost is 0.674327-------------\n",
      "---------Iteration 4,cost is 0.669978-------------\n",
      "---------Iteration 5,cost is 0.667738-------------\n",
      "---------Iteration 6,cost is 0.666471-------------\n",
      "---------Iteration 7,cost is 0.665657-------------\n",
      "---------Iteration 8,cost is 0.665053-------------\n",
      "---------Iteration 9,cost is 0.664551-------------\n",
      "---------Iteration 10,cost is 0.664097-------------\n",
      "---------Iteration 11,cost is 0.663668-------------\n",
      "---------Iteration 12,cost is 0.663253-------------\n",
      "---------Iteration 13,cost is 0.662846-------------\n",
      "---------Iteration 14,cost is 0.662446-------------\n",
      "---------Iteration 15,cost is 0.662049-------------\n",
      "---------Iteration 16,cost is 0.661658-------------\n",
      "---------Iteration 17,cost is 0.661270-------------\n",
      "---------Iteration 18,cost is 0.660885-------------\n",
      "---------Iteration 19,cost is 0.660505-------------\n",
      "---------Iteration 20,cost is 0.660128-------------\n",
      "---------Iteration 21,cost is 0.659754-------------\n",
      "---------Iteration 22,cost is 0.659384-------------\n",
      "---------Iteration 23,cost is 0.659017-------------\n",
      "---------Iteration 24,cost is 0.658654-------------\n",
      "---------Iteration 25,cost is 0.658294-------------\n",
      "---------Iteration 26,cost is 0.657937-------------\n",
      "---------Iteration 27,cost is 0.657584-------------\n",
      "---------Iteration 28,cost is 0.657234-------------\n",
      "---------Iteration 29,cost is 0.656887-------------\n",
      "---------Iteration 30,cost is 0.656543-------------\n",
      "---------Iteration 31,cost is 0.656203-------------\n",
      "---------Iteration 32,cost is 0.655866-------------\n",
      "---------Iteration 33,cost is 0.655531-------------\n",
      "---------Iteration 34,cost is 0.655200-------------\n",
      "---------Iteration 35,cost is 0.654872-------------\n",
      "---------Iteration 36,cost is 0.654547-------------\n",
      "---------Iteration 37,cost is 0.654225-------------\n",
      "---------Iteration 38,cost is 0.653905-------------\n",
      "---------Iteration 39,cost is 0.653589-------------\n",
      "---------Iteration 40,cost is 0.653275-------------\n",
      "---------Iteration 41,cost is 0.652965-------------\n",
      "---------Iteration 42,cost is 0.652657-------------\n",
      "---------Iteration 43,cost is 0.652352-------------\n",
      "---------Iteration 44,cost is 0.652050-------------\n",
      "---------Iteration 45,cost is 0.651750-------------\n",
      "---------Iteration 46,cost is 0.651453-------------\n",
      "---------Iteration 47,cost is 0.651159-------------\n",
      "---------Iteration 48,cost is 0.650867-------------\n",
      "---------Iteration 49,cost is 0.650578-------------\n",
      "---------Iteration 50,cost is 0.650292-------------\n",
      "---------Iteration 51,cost is 0.650008-------------\n",
      "---------Iteration 52,cost is 0.649727-------------\n",
      "---------Iteration 53,cost is 0.649449-------------\n",
      "---------Iteration 54,cost is 0.649172-------------\n",
      "---------Iteration 55,cost is 0.648899-------------\n",
      "---------Iteration 56,cost is 0.648627-------------\n",
      "---------Iteration 57,cost is 0.648358-------------\n",
      "---------Iteration 58,cost is 0.648092-------------\n",
      "---------Iteration 59,cost is 0.647828-------------\n",
      "---------Iteration 60,cost is 0.647566-------------\n",
      "---------Iteration 61,cost is 0.647307-------------\n",
      "---------Iteration 62,cost is 0.647049-------------\n",
      "---------Iteration 63,cost is 0.646795-------------\n",
      "---------Iteration 64,cost is 0.646542-------------\n",
      "---------Iteration 65,cost is 0.646291-------------\n",
      "---------Iteration 66,cost is 0.646043-------------\n",
      "---------Iteration 67,cost is 0.645797-------------\n",
      "---------Iteration 68,cost is 0.645553-------------\n",
      "---------Iteration 69,cost is 0.645312-------------\n",
      "---------Iteration 70,cost is 0.645072-------------\n",
      "---------Iteration 71,cost is 0.644835-------------\n",
      "---------Iteration 72,cost is 0.644599-------------\n",
      "---------Iteration 73,cost is 0.644366-------------\n",
      "---------Iteration 74,cost is 0.644134-------------\n",
      "---------Iteration 75,cost is 0.643905-------------\n",
      "---------Iteration 76,cost is 0.643678-------------\n",
      "---------Iteration 77,cost is 0.643452-------------\n",
      "---------Iteration 78,cost is 0.643229-------------\n",
      "---------Iteration 79,cost is 0.643007-------------\n",
      "---------Iteration 80,cost is 0.642788-------------\n",
      "---------Iteration 81,cost is 0.642570-------------\n",
      "---------Iteration 82,cost is 0.642354-------------\n",
      "---------Iteration 83,cost is 0.642140-------------\n",
      "---------Iteration 84,cost is 0.641928-------------\n",
      "---------Iteration 85,cost is 0.641718-------------\n",
      "---------Iteration 86,cost is 0.641510-------------\n",
      "---------Iteration 87,cost is 0.641303-------------\n",
      "---------Iteration 88,cost is 0.641098-------------\n",
      "---------Iteration 89,cost is 0.640895-------------\n",
      "---------Iteration 90,cost is 0.640693-------------\n",
      "---------Iteration 91,cost is 0.640494-------------\n",
      "---------Iteration 92,cost is 0.640296-------------\n",
      "---------Iteration 93,cost is 0.640099-------------\n",
      "---------Iteration 94,cost is 0.639905-------------\n",
      "---------Iteration 95,cost is 0.639712-------------\n",
      "---------Iteration 96,cost is 0.639520-------------\n",
      "---------Iteration 97,cost is 0.639331-------------\n",
      "---------Iteration 98,cost is 0.639142-------------\n",
      "---------Iteration 99,cost is 0.638956-------------\n",
      "---------Iteration 100,cost is 0.638771-------------\n",
      "---------Iteration 101,cost is 0.638587-------------\n",
      "---------Iteration 102,cost is 0.638406-------------\n",
      "---------Iteration 103,cost is 0.638225-------------\n",
      "---------Iteration 104,cost is 0.638046-------------\n",
      "---------Iteration 105,cost is 0.637869-------------\n",
      "---------Iteration 106,cost is 0.637693-------------\n",
      "---------Iteration 107,cost is 0.637519-------------\n",
      "---------Iteration 108,cost is 0.637346-------------\n",
      "---------Iteration 109,cost is 0.637174-------------\n",
      "---------Iteration 110,cost is 0.637004-------------\n",
      "---------Iteration 111,cost is 0.636835-------------\n",
      "---------Iteration 112,cost is 0.636668-------------\n",
      "---------Iteration 113,cost is 0.636502-------------\n",
      "---------Iteration 114,cost is 0.636338-------------\n",
      "---------Iteration 115,cost is 0.636175-------------\n",
      "---------Iteration 116,cost is 0.636013-------------\n",
      "---------Iteration 117,cost is 0.635852-------------\n",
      "---------Iteration 118,cost is 0.635693-------------\n",
      "---------Iteration 119,cost is 0.635535-------------\n",
      "---------Iteration 120,cost is 0.635379-------------\n",
      "---------Iteration 121,cost is 0.635223-------------\n",
      "---------Iteration 122,cost is 0.635069-------------\n",
      "---------Iteration 123,cost is 0.634916-------------\n",
      "---------Iteration 124,cost is 0.634765-------------\n",
      "---------Iteration 125,cost is 0.634615-------------\n",
      "---------Iteration 126,cost is 0.634466-------------\n",
      "---------Iteration 127,cost is 0.634318-------------\n",
      "---------Iteration 128,cost is 0.634171-------------\n",
      "---------Iteration 129,cost is 0.634026-------------\n",
      "---------Iteration 130,cost is 0.633881-------------\n",
      "---------Iteration 131,cost is 0.633738-------------\n",
      "---------Iteration 132,cost is 0.633596-------------\n",
      "---------Iteration 133,cost is 0.633455-------------\n",
      "---------Iteration 134,cost is 0.633316-------------\n",
      "---------Iteration 135,cost is 0.633177-------------\n",
      "---------Iteration 136,cost is 0.633040-------------\n",
      "---------Iteration 137,cost is 0.632903-------------\n",
      "---------Iteration 138,cost is 0.632768-------------\n",
      "---------Iteration 139,cost is 0.632634-------------\n",
      "---------Iteration 140,cost is 0.632501-------------\n",
      "---------Iteration 141,cost is 0.632369-------------\n",
      "---------Iteration 142,cost is 0.632238-------------\n",
      "---------Iteration 143,cost is 0.632108-------------\n",
      "---------Iteration 144,cost is 0.631979-------------\n",
      "---------Iteration 145,cost is 0.631851-------------\n",
      "---------Iteration 146,cost is 0.631724-------------\n",
      "---------Iteration 147,cost is 0.631598-------------\n",
      "---------Iteration 148,cost is 0.631473-------------\n",
      "---------Iteration 149,cost is 0.631349-------------\n",
      "---------Iteration 150,cost is 0.631226-------------\n",
      "---------Iteration 151,cost is 0.631104-------------\n",
      "---------Iteration 152,cost is 0.630983-------------\n",
      "---------Iteration 153,cost is 0.630863-------------\n",
      "---------Iteration 154,cost is 0.630744-------------\n",
      "---------Iteration 155,cost is 0.630626-------------\n",
      "---------Iteration 156,cost is 0.630509-------------\n",
      "---------Iteration 157,cost is 0.630392-------------\n",
      "---------Iteration 158,cost is 0.630277-------------\n",
      "---------Iteration 159,cost is 0.630162-------------\n",
      "---------Iteration 160,cost is 0.630049-------------\n",
      "---------Iteration 161,cost is 0.629936-------------\n",
      "---------Iteration 162,cost is 0.629824-------------\n",
      "---------Iteration 163,cost is 0.629713-------------\n",
      "---------Iteration 164,cost is 0.629603-------------\n",
      "---------Iteration 165,cost is 0.629493-------------\n",
      "---------Iteration 166,cost is 0.629385-------------\n",
      "---------Iteration 167,cost is 0.629277-------------\n",
      "---------Iteration 168,cost is 0.629170-------------\n",
      "---------Iteration 169,cost is 0.629064-------------\n",
      "---------Iteration 170,cost is 0.628959-------------\n",
      "---------Iteration 171,cost is 0.628855-------------\n",
      "---------Iteration 172,cost is 0.628751-------------\n",
      "---------Iteration 173,cost is 0.628648-------------\n",
      "---------Iteration 174,cost is 0.628546-------------\n",
      "---------Iteration 175,cost is 0.628445-------------\n",
      "---------Iteration 176,cost is 0.628345-------------\n",
      "---------Iteration 177,cost is 0.628245-------------\n",
      "---------Iteration 178,cost is 0.628146-------------\n",
      "---------Iteration 179,cost is 0.628048-------------\n",
      "---------Iteration 180,cost is 0.627950-------------\n",
      "---------Iteration 181,cost is 0.627854-------------\n",
      "---------Iteration 182,cost is 0.627758-------------\n",
      "---------Iteration 183,cost is 0.627662-------------\n",
      "---------Iteration 184,cost is 0.627568-------------\n",
      "---------Iteration 185,cost is 0.627474-------------\n",
      "---------Iteration 186,cost is 0.627381-------------\n",
      "---------Iteration 187,cost is 0.627288-------------\n",
      "---------Iteration 188,cost is 0.627197-------------\n",
      "---------Iteration 189,cost is 0.627106-------------\n",
      "---------Iteration 190,cost is 0.627015-------------\n",
      "---------Iteration 191,cost is 0.626925-------------\n",
      "---------Iteration 192,cost is 0.626836-------------\n",
      "---------Iteration 193,cost is 0.626748-------------\n",
      "---------Iteration 194,cost is 0.626660-------------\n",
      "---------Iteration 195,cost is 0.626573-------------\n",
      "---------Iteration 196,cost is 0.626487-------------\n",
      "---------Iteration 197,cost is 0.626401-------------\n",
      "---------Iteration 198,cost is 0.626316-------------\n",
      "---------Iteration 199,cost is 0.626231-------------\n",
      "predictions are [[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]]\n",
      "ground truth is [[1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n",
      "theta is  [[-1.80524242]\n",
      " [ 2.15175558]\n",
      " [ 2.12417826]]\n",
      "the accuracy is 0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Bad       0.67      1.00      0.80         2\n",
      "        Good       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.80         5\n",
      "   macro avg       0.83      0.83      0.80         5\n",
      "weighted avg       0.87      0.80      0.80         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "density = np.array([0.697,0.774,0.634,0.608,0.556,0.430,0.481,0.437,0.666,0.243,0.245,0.343,0.639,0.657,0.360,0.593,0.719]).reshape(-1,1)\n",
    "sugar_rate = np.array([0.460,0.376,0.264,0.318,0.215,0.237,0.149,0.211,0.091,0.267,0.057,0.099,0.161,0.198,0.370,0.042,0.103]).reshape(-1,1)\n",
    "\n",
    "xtrain = np.hstack((density, sugar_rate))\n",
    "xtrain = np.hstack((np.ones([density.shape[0],1]), xtrain))\n",
    "ytrain = np.array([1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0]).reshape(-1,1)\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(xtrain, ytrain, test_size=0.25, random_state=33)\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))\n",
    "\n",
    "#print(sigmoid(density))\n",
    "def logit_regression(theta,x,y,iteration=200,learning_rate=0.1,lbd=0.01):\n",
    "    for i in range(iteration):\n",
    "        theta = theta-learning_rate/y.shape[0]*(np.dot(x.transpose(),(sigmoid(np.dot(x,theta))-y))+lbd*theta)\n",
    "        cost = -1/y.shape[0]*(np.dot(y.transpose(),np.log(sigmoid(np.dot(x,theta))))+np.dot((1-y).transpose(),np.log(1-sigmoid(np.dot(x,theta)))))+lbd/(2*y.shape[0])*np.dot(theta.transpose(),theta)\n",
    "        print('---------Iteration %d,cost is %f-------------'%(i,cost))\n",
    "    return theta\n",
    "\n",
    "def predict(theta,x):\n",
    "    pre=np.zeros([x.shape[0],1])\n",
    "    for idx,valu in enumerate(np.dot(x,theta)):\n",
    "        if sigmoid(valu)>=0.5:\n",
    "            pre[idx]=1\n",
    "        else:\n",
    "            pre[idx]=0\n",
    "    return pre\n",
    "         \n",
    "theta_init=np.random.rand(3,1)\n",
    "theta=logit_regression(theta_init,xtrain,ytrain,learning_rate=1)\n",
    "pre=predict(theta,xtest)\n",
    "print('predictions are',pre)\n",
    "print('ground truth is',ytest)\n",
    "print('theta is ',theta)\n",
    "print('the accuracy is',np.mean(pre==ytest))\n",
    "print(classification_report(ytest,pre,target_names=['Bad','Good']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
